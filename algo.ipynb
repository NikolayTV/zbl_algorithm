{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, re, json, ast\n",
    "from llm_api_calls import send_message_to_gemini_async, RateLimiter, send_message_open_router\n",
    "from pprint import pprint\n",
    "from algo import base_start_dialog_algorithm, base_continue_dialog_algorithm, simulate_user_response_prompt, \\\n",
    "    student_card_template, send_message, extract_student_health_data_prompt, \\\n",
    "    generate_readable_history_from_end,  update_message_history_with_system_message, convert_gemini_history_to_open_router\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start algo question answer scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialog_count: 0\n",
      "\n",
      "\n",
      "USER:\n",
      " Q6sg5\n",
      "\n",
      "\n",
      "MODEL:\n",
      " Спасибо за предоставленный промокод. Теперь я могу приступить к сбору необходимой информации для создания вашего алгоритма. Давайте начнем с вашего имени и возраста.\n",
      "{'provider': 'gemini', 'input_tokens': 4, 'output_tokens': 34}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ConversationManager.send_message_to_user_telegram() missing 1 required positional argument: 'model_message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 131\u001b[0m\n\u001b[1;32m    129\u001b[0m model_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m conv_manager\u001b[38;5;241m.\u001b[39mprocess_model_interaction(user_query)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m conv_manager\u001b[38;5;241m.\u001b[39mupdate_dialog_status()\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mconv_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message_to_user_telegram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_message\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m conv_manager\u001b[38;5;241m.\u001b[39mupdate_student_card_from_message_history()\n",
      "\u001b[0;31mTypeError\u001b[0m: ConversationManager.send_message_to_user_telegram() missing 1 required positional argument: 'model_message'"
     ]
    }
   ],
   "source": [
    "class ConversationManager:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.rate_limiter = RateLimiter(13, 14)\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # user info\n",
    "        self.telegram_user_id = []\n",
    "\n",
    "        # conversaion info\n",
    "        self.message_history = []\n",
    "        self.usage_history = []\n",
    "        self.dialog_count = 0\n",
    "        self.dialog_status = 'continue'\n",
    "        self.extraction_usage_history = []\n",
    "\n",
    "        # extraction\n",
    "        self.student_card = {}\n",
    "\n",
    "\n",
    "    async def start_conversation(self):\n",
    "        \"\"\"\n",
    "        Начинает диалог с заготовленных сообщений\n",
    "        \"\"\"\n",
    "        self.student_card = student_card_template().copy()\n",
    "        prompted_message = base_start_dialog_algorithm().replace(\"$STUDENT_CARD\", str(self.student_card))\n",
    "        self.message_history.append({\"role\": \"user\", \"parts\": [prompted_message]})\n",
    "        self.message_history.append({\"role\": \"model\", \"parts\": ['Здравствуйте! Меня зовут Аика, и я очень рада приветствовать вас в нашем диалоге по улучшению здоровья. Прежде чем начать, мне необходимо проверить ваш промокод, чтобы получить доступ к созданию алгоритма. Ваш промокод находится в 9 уроке.']})\n",
    "\n",
    "\n",
    "    async def process_model_interaction(self, user_query):\n",
    "        if user_query.strip() == '':\n",
    "            user_query = \"Расскажи шутку. А потом давай продолжим\"\n",
    "        \n",
    "        await self.get_message_from_model(user_query, provider='gemini')\n",
    "        model_message = self.message_history[-1]['parts'][0]\n",
    "        return model_message\n",
    "\n",
    "    \n",
    "    async def get_message_from_model(self, user_query, provider='gemini'):\n",
    "        self.message_history.append({\"role\": \"user\", \"parts\": [user_query]})\n",
    "\n",
    "        if provider == 'gemini':\n",
    "            response = await send_message_to_gemini_async(self.message_history, rate_limiter=self.rate_limiter, generation_params={\"temperature\": 0.2, \"top_k\":3})\n",
    "        elif provider == 'router_sonnet':\n",
    "            openrouter_history = convert_gemini_history_to_open_router(self.message_history)\n",
    "            response = await send_message_open_router(openrouter_history, rate_limiter=self.rate_limiter, model=\"anthropic/claude-3-sonnet\")\n",
    "        \n",
    "\n",
    "        input_tokens = response.get('input_tokens')\n",
    "        output_tokens = response.get('output_tokens')\n",
    "        answer_text = response.get('text_response')\n",
    "\n",
    "        self.message_history.append({\"role\": \"model\", \"parts\": [answer_text]})\n",
    "        self.usage_history.append({\"provider\": provider, \"query\": user_query, \"answer\": answer_text, \"input_tokens\": input_tokens, \"output_tokens\": output_tokens})\n",
    "        if self.verbose:\n",
    "            print('\\n\\nUSER:\\n', user_query)\n",
    "            print('\\n\\nMODEL:\\n', answer_text)\n",
    "            print({\"provider\": provider, \"input_tokens\": input_tokens, \"output_tokens\": output_tokens})\n",
    "\n",
    "\n",
    "    async def update_student_card_from_message_history(self, dialogs_num=5):\n",
    "        model_message = self.message_history[-1]['parts'][0]\n",
    "\n",
    "        if (self.dialog_count % 4 == 0 and self.dialog_count > 0) or ('next_step' in model_message.lower()):\n",
    "        \n",
    "            readable_history = await generate_readable_history_from_end(messages=self.message_history, dialogs_num=dialogs_num)\n",
    "            extract_student_health_data_prompted = extract_student_health_data_prompt().replace(\"$DIALOG\", readable_history).replace(\"$STUDENT_CARD\", str(self.student_card))\n",
    "            messages = [{\"role\": \"model\", \"parts\": [extract_student_health_data_prompted]}]\n",
    "            response = await send_message_to_gemini_async(messages, rate_limiter=self.rate_limiter, generation_params={\"temperature\": 0, \"top_k\":1})\n",
    "\n",
    "            input_tokens = response.get('input_tokens')\n",
    "            output_tokens = response.get('output_tokens')\n",
    "            answer_text = response.get('text_response')\n",
    "\n",
    "            try:\n",
    "                # UPDATE STUDENT CARD\n",
    "                new_info = json.loads(answer_text.strip('```json').strip('```'))\n",
    "                self.student_card.update(new_info)\n",
    "            except:\n",
    "                new_info = f'Не найдена. Текст ответа: {response}'\n",
    "\n",
    "            if self.verbose:\n",
    "                print('response:', response)\n",
    "\n",
    "            # ADD TO HISTORY\n",
    "            self.extraction_usage_history.append({\"provider\": 'gemini', \"query\": extract_student_health_data_prompted, \"answer\": answer_text, \"input_tokens\": input_tokens, \"output_tokens\": output_tokens})\n",
    "\n",
    "    \n",
    "    async def update_dialog_status(self):\n",
    "        model_message = self.message_history[-1]['parts'][0]\n",
    "        \n",
    "        if 'terminate' in model_message.lower():   \n",
    "            self.dialog_status = 'terminate'\n",
    "        elif 'next_step' in model_message.lower(): \n",
    "            self.dialog_status = 'next_step'\n",
    "\n",
    "\n",
    "    async def simulate_user_response(self):\n",
    "        user_query = simulate_user_response_prompt().replace(\"$DOCTOR_QUESTION\", self.message_history[-1]['parts'][0])\n",
    "        response_user = await send_message_to_gemini_async(history = [{'role': 'user', 'parts': [user_query]}])\n",
    "        user_query = response_user.get('text_response')\n",
    "        return user_query\n",
    "    \n",
    "    async def send_message_to_user_telegram(self, model_message):\n",
    "        # self.user_id\n",
    "        pass\n",
    "\n",
    "    async def run(self):\n",
    "        await self.start_conversation()\n",
    "        while self.dialog_status not in ['terminate', 'next_step']:\n",
    "            if self.verbose: \n",
    "                print(f'dialog_count: {self.dialog_count}')\n",
    "            user_query = await self.simulate_user_response()\n",
    "            model_message = await self.process_model_interaction(user_query)\n",
    "            await self.send_message_to_user_telegram(model_message)\n",
    "            await self.update_dialog_status()\n",
    "            await self.update_student_card_from_message_history()\n",
    "\n",
    "            self.dialog_count += 1\n",
    "\n",
    "# conv_manager = ConversationManager()\n",
    "# try:\n",
    "#     await conv_manager.run()\n",
    "# except KeyboardInterrupt:\n",
    "#     print('Stopping due to KeyboardInterrupt')\n",
    "\n",
    "conv_manager = ConversationManager(verbose=True)\n",
    "\n",
    "\n",
    "await conv_manager.start_conversation()\n",
    "while conv_manager.dialog_status not in ['terminate', 'next_step']:\n",
    "    if conv_manager.verbose: \n",
    "        print(f'dialog_count: {conv_manager.dialog_count}')\n",
    "    user_query = await conv_manager.simulate_user_response()\n",
    "    model_message = await conv_manager.process_model_interaction(user_query)\n",
    "    await conv_manager.send_message_to_user_telegram(model_message)\n",
    "    await conv_manager.update_dialog_status()\n",
    "    await conv_manager.update_student_card_from_message_history()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description of card': {'value': 'карточка о здоровье, хранических заболеваниях, выбранном лечении'},\n",
       " 'Промокод': {'value': ''},\n",
       " 'Имя и возраст': {'value': 'Анна, 27 лет'},\n",
       " 'Цели по здоровью': {'value': 'Лучше понимать свое тело и потребности в питании'},\n",
       " 'Артериальное давление': {'value': '120/80, гипертония под контролем'},\n",
       " 'Тип сокращения желчного пузыря': {'value': 'Нормокинетический'},\n",
       " 'Выбранная трава желчегонная': {'value': 'Тысячелистник'},\n",
       " 'Желчегонная гимнастика': {'value': 'Будет выполнять в ближайшее время'},\n",
       " 'Витамин Д': {'value': '400 МЕ в день'},\n",
       " 'Время принятия лимфатического душа': {'value': 'Вечером'},\n",
       " 'Результаты копрограммы': {'value': '',\n",
       "  'instruction': 'Спросить о результатах копрограммы, если они имеются.'},\n",
       " 'Хронические заболевания или противопоказания': {'value': 'легкая астма'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_card = conv_manager.student_card\n",
    "message_history = conv_manager.message_history\n",
    "usage_history = conv_manager.usage_history\n",
    "extraction_usage_history = conv_manager.extraction_usage_history\n",
    "\n",
    "student_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOODO если желчный удален то не спрашивать про желчегонную траву и желчегонную гимнастику\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us['input_tokens'].sum() 47084\n",
      "us['output_tokens'].sum() 2987\n",
      "price 0.18605700000000003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>conversation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1427</td>\n",
       "      <td>127</td>\n",
       "      <td>1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1561</td>\n",
       "      <td>84</td>\n",
       "      <td>3199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1693</td>\n",
       "      <td>130</td>\n",
       "      <td>5022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1860</td>\n",
       "      <td>170</td>\n",
       "      <td>7052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2068</td>\n",
       "      <td>97</td>\n",
       "      <td>9217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2238</td>\n",
       "      <td>241</td>\n",
       "      <td>11696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2522</td>\n",
       "      <td>202</td>\n",
       "      <td>14420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2780</td>\n",
       "      <td>200</td>\n",
       "      <td>17400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3007</td>\n",
       "      <td>212</td>\n",
       "      <td>20619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3237</td>\n",
       "      <td>233</td>\n",
       "      <td>24089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3489</td>\n",
       "      <td>262</td>\n",
       "      <td>27840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3796</td>\n",
       "      <td>272</td>\n",
       "      <td>31908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4087</td>\n",
       "      <td>171</td>\n",
       "      <td>36166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4264</td>\n",
       "      <td>154</td>\n",
       "      <td>40584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4435</td>\n",
       "      <td>158</td>\n",
       "      <td>45177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4620</td>\n",
       "      <td>274</td>\n",
       "      <td>50071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_tokens  output_tokens  conversation_tokens\n",
       "0           1427            127                 1554\n",
       "1           1561             84                 3199\n",
       "2           1693            130                 5022\n",
       "3           1860            170                 7052\n",
       "4           2068             97                 9217\n",
       "5           2238            241                11696\n",
       "6           2522            202                14420\n",
       "7           2780            200                17400\n",
       "8           3007            212                20619\n",
       "9           3237            233                24089\n",
       "10          3489            262                27840\n",
       "11          3796            272                31908\n",
       "12          4087            171                36166\n",
       "13          4264            154                40584\n",
       "14          4435            158                45177\n",
       "15          4620            274                50071"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SONNET\n",
    "import pandas as pd\n",
    "us = pd.DataFrame(usage_history)\n",
    "print(\"us['input_tokens'].sum()\", us['input_tokens'].sum())\n",
    "print(\"us['output_tokens'].sum()\", us['output_tokens'].sum())\n",
    "print(\"price\", us['input_tokens'].sum()/1000 * 0.003 + us['output_tokens'].sum()/1000 * 0.015)\n",
    "us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>conversation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>979</td>\n",
       "      <td>47</td>\n",
       "      <td>1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>51</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>87</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>1434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>1494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>108</td>\n",
       "      <td>1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11</td>\n",
       "      <td>51</td>\n",
       "      <td>2172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>2256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_tokens  output_tokens  conversation_tokens\n",
       "0            979             47                 1026\n",
       "1             18             30                 1074\n",
       "2              4             51                 1129\n",
       "3             11             39                 1179\n",
       "4             14             87                 1280\n",
       "5              3             60                 1343\n",
       "6              5             86                 1434\n",
       "7              6             54                 1494\n",
       "8              4            141                 1639\n",
       "9             17            108                 1764\n",
       "10            13             83                 1860\n",
       "11            38             56                 1954\n",
       "12             3             67                 2024\n",
       "13             4             82                 2110\n",
       "14            11             51                 2172\n",
       "15            12             72                 2256"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GEMINI\n",
    "us.to_csv('gemini_token_usage_16msgs.csv')\n",
    "us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
